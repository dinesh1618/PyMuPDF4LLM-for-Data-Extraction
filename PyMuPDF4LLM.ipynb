{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d0d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66e7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491901c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c1a",
   "metadata": {},
   "source": [
    "Get All Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a98a4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2[======                                  ] ( 4/23=[========                                ] ( 5/23=[==========                              ] ( 6/23=[============                            ] ( 7/23[=============                           ] ( 8/2=[===============                         ] ( 9/2=[=================                       ] (10/2=[===================                     ] (11/2[====================                    ] (12/23=[======================                  ] (13/23=[========================                ] (14/23=[==========================              ] (15/23[===========================             ] (16/2=[=============================           ] (17/2=[===============================         ] (18/2=[=================================       ] (19/2[==================================      ] (20/23=[====================================    ] (21/23=[======================================  ] (22/23[========================================] (23/23]\n"
     ]
    }
   ],
   "source": [
    "md_text = pymupdf4llm.to_markdown(doc=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf062f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(/)Jay Alammar (/)](https://jalammar.github.io/)\\n\\nVisualizing machine learning one concept at a time.\\n[@JayAlammar (https://twitter.com/JayAlammar) on Twitter. YouTube Channel](https://twitter.com/JayAlammar)\\n[(https://www.youtube.com/channel/UCmOwsoHty5PrmE-3QhUBfPQ)](https://www.youtube.com/channel/UCmOwsoHty5PrmE-3QhUBfPQ)\\n\\n# The Illustrated Transformer\\n\\n\\n[Blog (/)](https://jalammar.github.io/) [About (/about)](https://jalammar.github.io/about)\\n\\n\\n[Discussions: Hacker News (65 points, 4 comme'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849241cd",
   "metadata": {},
   "source": [
    "Save Markdown to a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7739596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34360998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31779"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlib.Path(\"output.md\").write_bytes(md_text.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dd21b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathlib.Path(\"output.md\").write_text(md_text, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee151f9a",
   "metadata": {},
   "source": [
    "Extract only Specific Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efb96a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/2===================[====================                    ] (1/2===================[========================================] (2/2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'### A High-Level Look\\n\\nLet’s begin by looking at the model as a single black box. In a machine translation application, it would take a\\nsentence in one language, and output its translation in another.\\n\\nPopping open that Optimus Prime goodness, we see an encoding component, a decoding component, and\\nconnections between them.\\n\\nThe encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing\\nmagical about the number six, one can definitely experiment with other arrangements). The decoding component is a\\nstack of decoders of the same number.\\n\\n\\n-----\\n\\nThe encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sublayers:\\n\\nThe encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the\\ninput sentence as it encodes a specific word. We’ll look closer at self-attention later in the post.\\n\\nThe outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network\\nis independently applied to each position.\\n\\nThe decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant\\n[parts of the input sentence (similar what attention does in seq2seq models (https://jalammar.github.io/visualizing-](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\\n[neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)).](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\\n\\n\\n-----\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymupdf4llm.to_markdown(doc=file_path, pages=[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ebd86",
   "metadata": {},
   "source": [
    "Extract Documents for LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b445332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "677fc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_reader = pymupdf4llm.LlamaMarkdownReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7195e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n"
     ]
    }
   ],
   "source": [
    "llama_docs = llama_reader.load_data(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f571fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='31099942-eb6e-425b-8187-9b2f26cf9f1f', embedding=None, metadata={'format': 'PDF 1.4', 'title': 'The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36', 'producer': 'Skia/PDF m124', 'creationDate': \"D:20240501121657+00'00'\", 'modDate': \"D:20240501121657+00'00'\", 'trapped': '', 'encryption': None, 'page': 1, 'total_pages': 23, 'file_path': 'D:\\\\ML\\\\Langgraph-end-to-end\\\\The Illustrated Transformer.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[(/)Jay Alammar (/)](https://jalammar.github.io/)\\n\\nVisualizing machine learning one concept at a time.\\n[@JayAlammar (https://twitter.com/JayAlammar) on Twitter. YouTube Channel](https://twitter.com/JayAlammar)\\n[(https://www.youtube.com/channel/UCmOwsoHty5PrmE-3QhUBfPQ)](https://www.youtube.com/channel/UCmOwsoHty5PrmE-3QhUBfPQ)\\n\\n# The Illustrated Transformer\\n\\n\\n[Blog (/)](https://jalammar.github.io/) [About (/about)](https://jalammar.github.io/about)\\n\\n\\n[Discussions: Hacker News (65 points, 4 comments) (https://news.ycombinator.com/item?id=18351674), Reddit r/MachineLearning (29 points, 3 comments)](https://news.ycombinator.com/item?id=18351674)\\n\\n[(https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/)](https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/)\\n\\n[Translations: Arabic (https://www.mundhor.site/post/post14), Chinese (Simplified) 1 (https://blog.csdn.net/yujianmin1990/article/details/85221271), Chinese](https://www.mundhor.site/post/post14)\\n\\n[(Simplified) 2 (https://blog.csdn.net/qq_36667170/article/details/124359818), French 1 (https://a-coles.github.io/2020/11/15/transformer-illustre.html), French](https://blog.csdn.net/qq_36667170/article/details/124359818)\\n\\n[2 (https://lbourdois.github.io/blog/nlp/Transformer/), Italian (https://medium.com/@val.mannucci/il-transformer-illustrato-it-37a78e3e2348), Japanese](https://lbourdois.github.io/blog/nlp/Transformer/)\\n\\n[(https://tips-memo.com/translation-jayalmmar-transformer), Korean (https://nlpinkorean.github.io/illustrated-transformer/), Persian](https://tips-memo.com/translation-jayalmmar-transformer)\\n\\n[(http://dml.qom.ac.ir/2022/05/17/illustrated-transformer/), Russian (https://habr.com/ru/post/486358/), Spanish 1](http://dml.qom.ac.ir/2022/05/17/illustrated-transformer/)\\n\\n[(https://www.ibidemgroup.com/edu/transformer-ilustrado-jay-alammar/), Spanish 2 (https://hackernoon.com/el-transformador-ilustrado-una-traduccion-al-](https://www.ibidemgroup.com/edu/transformer-ilustrado-jay-alammar/)\\n\\n[espanol-0y73wwp), Vietnamese (https://trituenhantao.io/tin-tuc/minh-hoa-transformer/)](https://hackernoon.com/el-transformador-ilustrado-una-traduccion-al-espanol-0y73wwp)\\n\\n[Watch: MIT’s Deep Learning State of the Art (https://youtu.be/53YvP6gdD7U?t=432) lecture referencing this post](https://youtu.be/53YvP6gdD7U?t=432)\\n\\n[Featured in courses at Stanford (https://web.stanford.edu/class/cs224n/), Harvard (https://scholar.harvard.edu/binxuw/classes/machine-learning-](https://web.stanford.edu/class/cs224n/)\\n\\n[scratch/materials/transformers), MIT (https://ocw.mit.edu/courses/6-s897-machine-learning-for-healthcare-spring-](https://scholar.harvard.edu/binxuw/classes/machine-learning-scratch/materials/transformers)\\n\\n[2019/d39a6eed387ee90b1f72a01949c35c7b_MIT6_S897S19_lec8.pdf), Princeton (https://www.cs.princeton.edu/courses/archive/fall22/cos597G/), CMU](https://ocw.mit.edu/courses/6-s897-machine-learning-for-healthcare-spring-2019/d39a6eed387ee90b1f72a01949c35c7b_MIT6_S897S19_lec8.pdf)\\n\\n[(https://www.cs.cmu.edu/~leili/course/mldl22w/14-Transformer.pdf) and others](https://www.cs.cmu.edu/~leili/course/mldl22w/14-Transformer.pdf)\\n\\n[In the previous post, we looked at Attention (https://jalammar.github.io/visualizing-neural-machine-translation-](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\\n[mechanics-of-seq2seq-models-with-attention/) – a ubiquitous method in modern deep learning models. Attention is a](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\\nconcept that helped improve the performance of neural machine translation applications. In this post, we will look at\\n**The Transformer – a model that uses attention to boost the speed with which these models can be trained. The**\\nTransformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit,\\nhowever, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation\\n[to use The Transformer as a reference model to use their Cloud TPU (https://cloud.google.com/tpu/) offering. So let’s](https://cloud.google.com/tpu/)\\ntry to break the model apart and look at how it functions.\\n\\n[The Transformer was proposed in the paper Attention is All You Need (https://arxiv.org/abs/1706.03762). A TensorFlow](https://arxiv.org/abs/1706.03762)\\n[implementation of it is available as a part of the Tensor2Tensor (https://github.com/tensorflow/tensor2tensor) package.](https://github.com/tensorflow/tensor2tensor)\\n[Harvard’s NLP group created a guide annotating the paper with PyTorch implementation](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\\n[(http://nlp.seas.harvard.edu/2018/04/03/attention.html). In this post, we will attempt to oversimplify things a bit and](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\\nintroduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of\\nthe subject matter.\\n\\n**2020 Update: I’ve created a “Narrated Transformer” video which is a gentler approach to the topic:**\\n\\n\\n-----\\n\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ac2558f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(/)Jay Alammar (/)](https://jalammar.github.io/)\\n\\nVisualizing machine learning one concept at a time.\\n[@JayAlammar (https://twitter.com/JayAlammar) on Twitter. YouTube Channel](https://twitter.com/JayAlammar)\\n[(https://www.youtube.com/channel/UCmOwsoHty5PrmE-3QhUBfPQ)](https://www.youtube.com/channel/UCmOwsoHty5PrmE-3QhUBfPQ)\\n\\n# The Illustrated Transformer\\n\\n\\n[Blog (/)](https://jalammar.github.io/) [About (/about)](https://jalammar.github.io/about)\\n\\n\\n[Discussions: Hacker News (65 points, 4 comments) (https://news.ycombinator.com/item?id=18351674), Reddit r/MachineLearning (29 points, 3 comments)](https://news.ycombinator.com/item?id=18351674)\\n\\n[(https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/)](https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/)\\n\\n[Translations: Arabic (https://www.mundhor.site/post/post14), Chinese (Simplified) 1 (https://blog.csdn.net/yujianmin1990/article/details/85221271), Chinese](https://www.mundhor.site/post/post14)\\n\\n[(Simplified) 2 (https://blog.csdn.net/qq_36667170/article/details/124359818), French 1 (https://a-coles.github.io/2020/11/15/transformer-illustre.html), French](https://blog.csdn.net/qq_36667170/article/details/124359818)\\n\\n[2 (https://lbourdois.github.io/blog/nlp/Transformer/), Italian (https://medium.com/@val.mannucci/il-transformer-illustrato-it-37a78e3e2348), Japanese](https://lbourdois.github.io/blog/nlp/Transformer/)\\n\\n[(https://tips-memo.com/translation-jayalmmar-transformer), Korean (https://nlpinkorean.github.io/illustrated-transformer/), Persian](https://tips-memo.com/translation-jayalmmar-transformer)\\n\\n[(http://dml.qom.ac.ir/2022/05/17/illustrated-transformer/), Russian (https://habr.com/ru/post/486358/), Spanish 1](http://dml.qom.ac.ir/2022/05/17/illustrated-transformer/)\\n\\n[(https://www.ibidemgroup.com/edu/transformer-ilustrado-jay-alammar/), Spanish 2 (https://hackernoon.com/el-transformador-ilustrado-una-traduccion-al-](https://www.ibidemgroup.com/edu/transformer-ilustrado-jay-alammar/)\\n\\n[espanol-0y73wwp), Vietnamese (https://trituenhantao.io/tin-tuc/minh-hoa-transformer/)](https://hackernoon.com/el-transformador-ilustrado-una-traduccion-al-espanol-0y73wwp)\\n\\n[Watch: MIT’s Deep Learning State of the Art (https://youtu.be/53YvP6gdD7U?t=432) lecture referencing this post](https://youtu.be/53YvP6gdD7U?t=432)\\n\\n[Featured in courses at Stanford (https://web.stanford.edu/class/cs224n/), Harvard (https://scholar.harvard.edu/binxuw/classes/machine-learning-](https://web.stanford.edu/class/cs224n/)\\n\\n[scratch/materials/transformers), MIT (https://ocw.mit.edu/courses/6-s897-machine-learning-for-healthcare-spring-](https://scholar.harvard.edu/binxuw/classes/machine-learning-scratch/materials/transformers)\\n\\n[2019/d39a6eed387ee90b1f72a01949c35c7b_MIT6_S897S19_lec8.pdf), Princeton (https://www.cs.princeton.edu/courses/archive/fall22/cos597G/), CMU](https://ocw.mit.edu/courses/6-s897-machine-learning-for-healthcare-spring-2019/d39a6eed387ee90b1f72a01949c35c7b_MIT6_S897S19_lec8.pdf)\\n\\n[(https://www.cs.cmu.edu/~leili/course/mldl22w/14-Transformer.pdf) and others](https://www.cs.cmu.edu/~leili/course/mldl22w/14-Transformer.pdf)\\n\\n[In the previous post, we looked at Attention (https://jalammar.github.io/visualizing-neural-machine-translation-](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\\n[mechanics-of-seq2seq-models-with-attention/) – a ubiquitous method in modern deep learning models. Attention is a](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\\nconcept that helped improve the performance of neural machine translation applications. In this post, we will look at\\n**The Transformer – a model that uses attention to boost the speed with which these models can be trained. The**\\nTransformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit,\\nhowever, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation\\n[to use The Transformer as a reference model to use their Cloud TPU (https://cloud.google.com/tpu/) offering. So let’s](https://cloud.google.com/tpu/)\\ntry to break the model apart and look at how it functions.\\n\\n[The Transformer was proposed in the paper Attention is All You Need (https://arxiv.org/abs/1706.03762). A TensorFlow](https://arxiv.org/abs/1706.03762)\\n[implementation of it is available as a part of the Tensor2Tensor (https://github.com/tensorflow/tensor2tensor) package.](https://github.com/tensorflow/tensor2tensor)\\n[Harvard’s NLP group created a guide annotating the paper with PyTorch implementation](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\\n[(http://nlp.seas.harvard.edu/2018/04/03/attention.html). In this post, we will attempt to oversimplify things a bit and](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\\nintroduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of\\nthe subject matter.\\n\\n**2020 Update: I’ve created a “Narrated Transformer” video which is a gentler approach to the topic:**\\n\\n\\n-----\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_docs[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a581b1",
   "metadata": {},
   "source": [
    "Extract Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa0c13aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2[======                                  ] ( 4/23=[========                                ] ( 5/23=[==========                              ] ( 6/23=[============                            ] ( 7/23[=============                           ] ( 8/2=[===============                         ] ( 9/2=[=================                       ] (10/2=[===================                     ] (11/2[====================                    ] (12/23=[======================                  ] (13/23=[========================                ] (14/23=[==========================              ] (15/23[===========================             ] (16/2=[=============================           ] (17/2=[===============================         ] (18/2=[=================================       ] (19/2[==================================      ] (20/23=[====================================    ] (21/23=[======================================  ] (22/23[========================================] (23/23]\n"
     ]
    }
   ],
   "source": [
    "mg_text_images = pymupdf4llm.to_markdown(\n",
    "    doc=file_path,\n",
    "    write_images=True,\n",
    "    image_path=\"Images\",\n",
    "    image_format=\"png\",\n",
    "    page_chunks=True,\n",
    "    dpi=300 #desired resolution for generated images.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c09a69b",
   "metadata": {},
   "source": [
    "Chunking Data and Extrcating it with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b26a90ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/2===================[====================                    ] (1/2===================[========================================] (2/2]\n"
     ]
    }
   ],
   "source": [
    "md_text_chunks = pymupdf4llm.to_markdown(doc=file_path, pages=[1, 2], page_chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e159aa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'format': 'PDF 1.4',\n",
       "  'title': 'The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.',\n",
       "  'author': '',\n",
       "  'subject': '',\n",
       "  'keywords': '',\n",
       "  'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',\n",
       "  'producer': 'Skia/PDF m124',\n",
       "  'creationDate': \"D:20240501121657+00'00'\",\n",
       "  'modDate': \"D:20240501121657+00'00'\",\n",
       "  'trapped': '',\n",
       "  'encryption': None,\n",
       "  'file_path': 'D:\\\\ML\\\\Langgraph-end-to-end\\\\The Illustrated Transformer.pdf',\n",
       "  'page_count': 23,\n",
       "  'page': 2},\n",
       " 'toc_items': [],\n",
       " 'tables': [],\n",
       " 'images': [{'number': 6,\n",
       "   'bbox': Rect(116.75000762939453, 426.7498779296875, 494.7500305175781, 663.7498779296875),\n",
       "   'transform': (378.0000305175781,\n",
       "    0.0,\n",
       "    -0.0,\n",
       "    237.00001525878906,\n",
       "    116.75000762939453,\n",
       "    426.7498779296875),\n",
       "   'width': 756,\n",
       "   'height': 474,\n",
       "   'colorspace': 3,\n",
       "   'cs-name': 'ICCBased(RGB,Google/Skia/3C3AA278A22CB84C7D076EDD085A2143)',\n",
       "   'xres': 96,\n",
       "   'yres': 96,\n",
       "   'bpc': 8,\n",
       "   'size': 65604},\n",
       "  {'number': 4,\n",
       "   'bbox': Rect(70.75, 261.2498779296875, 540.75, 384.2498779296875),\n",
       "   'transform': (470.0000305175781,\n",
       "    0.0,\n",
       "    -0.0,\n",
       "    123.00001525878906,\n",
       "    70.75,\n",
       "    261.2498779296875),\n",
       "   'width': 1127,\n",
       "   'height': 294,\n",
       "   'colorspace': 3,\n",
       "   'cs-name': 'ICCBased(RGB,Google/Skia/3C3AA278A22CB84C7D076EDD085A2143)',\n",
       "   'xres': 96,\n",
       "   'yres': 96,\n",
       "   'bpc': 8,\n",
       "   'size': 70914},\n",
       "  {'number': 0,\n",
       "   'bbox': Rect(196.0800018310547, 50.0, 370.55999755859375, 50.63999938964844),\n",
       "   'transform': (174.47999572753906,\n",
       "    0.0,\n",
       "    -0.0,\n",
       "    11.75999927520752,\n",
       "    196.0800018310547,\n",
       "    38.880001068115234),\n",
       "   'width': 727,\n",
       "   'height': 49,\n",
       "   'colorspace': 1,\n",
       "   'cs-name': 'DeviceGray',\n",
       "   'xres': 96,\n",
       "   'yres': 96,\n",
       "   'bpc': 8,\n",
       "   'size': 3350}],\n",
       " 'graphics': [],\n",
       " 'text': '### A High-Level Look\\n\\nLet’s begin by looking at the model as a single black box. In a machine translation application, it would take a\\nsentence in one language, and output its translation in another.\\n\\nPopping open that Optimus Prime goodness, we see an encoding component, a decoding component, and\\nconnections between them.\\n\\nThe encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing\\nmagical about the number six, one can definitely experiment with other arrangements). The decoding component is a\\nstack of decoders of the same number.\\n\\n\\n-----\\n\\n',\n",
       " 'words': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_text_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434cf05",
   "metadata": {},
   "source": [
    "Detailed Word-by-Word Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18bdb693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\ML\\Langgraph-end-to-end\\The Illustrated Transformer.pdf...\n",
      "[                                        ] (0/2===================[====================                    ] (1/2===================[========================================] (2/2]\n"
     ]
    }
   ],
   "source": [
    "md_text_words = pymupdf4llm.to_markdown(doc=file_path, pages=[1, 2], extract_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69b61c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'format': 'PDF 1.4',\n",
       "   'title': 'The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',\n",
       "   'producer': 'Skia/PDF m124',\n",
       "   'creationDate': \"D:20240501121657+00'00'\",\n",
       "   'modDate': \"D:20240501121657+00'00'\",\n",
       "   'trapped': '',\n",
       "   'encryption': None,\n",
       "   'file_path': 'D:\\\\ML\\\\Langgraph-end-to-end\\\\The Illustrated Transformer.pdf',\n",
       "   'page_count': 23,\n",
       "   'page': 2},\n",
       "  'toc_items': [],\n",
       "  'tables': [],\n",
       "  'images': [{'number': 6,\n",
       "    'bbox': Rect(116.75000762939453, 426.7498779296875, 494.7500305175781, 663.7498779296875),\n",
       "    'transform': (378.0000305175781,\n",
       "     0.0,\n",
       "     -0.0,\n",
       "     237.00001525878906,\n",
       "     116.75000762939453,\n",
       "     426.7498779296875),\n",
       "    'width': 756,\n",
       "    'height': 474,\n",
       "    'colorspace': 3,\n",
       "    'cs-name': 'ICCBased(RGB,Google/Skia/3C3AA278A22CB84C7D076EDD085A2143)',\n",
       "    'xres': 96,\n",
       "    'yres': 96,\n",
       "    'bpc': 8,\n",
       "    'size': 65604},\n",
       "   {'number': 4,\n",
       "    'bbox': Rect(70.75, 261.2498779296875, 540.75, 384.2498779296875),\n",
       "    'transform': (470.0000305175781,\n",
       "     0.0,\n",
       "     -0.0,\n",
       "     123.00001525878906,\n",
       "     70.75,\n",
       "     261.2498779296875),\n",
       "    'width': 1127,\n",
       "    'height': 294,\n",
       "    'colorspace': 3,\n",
       "    'cs-name': 'ICCBased(RGB,Google/Skia/3C3AA278A22CB84C7D076EDD085A2143)',\n",
       "    'xres': 96,\n",
       "    'yres': 96,\n",
       "    'bpc': 8,\n",
       "    'size': 70914},\n",
       "   {'number': 0,\n",
       "    'bbox': Rect(196.0800018310547, 50.0, 370.55999755859375, 50.63999938964844),\n",
       "    'transform': (174.47999572753906,\n",
       "     0.0,\n",
       "     -0.0,\n",
       "     11.75999927520752,\n",
       "     196.0800018310547,\n",
       "     38.880001068115234),\n",
       "    'width': 727,\n",
       "    'height': 49,\n",
       "    'colorspace': 1,\n",
       "    'cs-name': 'DeviceGray',\n",
       "    'xres': 96,\n",
       "    'yres': 96,\n",
       "    'bpc': 8,\n",
       "    'size': 3350}],\n",
       "  'graphics': [],\n",
       "  'text': '### A High-Level Look\\n\\nLet’s begin by looking at the model as a single black box. In a machine translation application, it would take a\\nsentence in one language, and output its translation in another.\\n\\nPopping open that Optimus Prime goodness, we see an encoding component, a decoding component, and\\nconnections between them.\\n\\nThe encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing\\nmagical about the number six, one can definitely experiment with other arrangements). The decoding component is a\\nstack of decoders of the same number.\\n\\n\\n-----\\n\\n',\n",
       "  'words': [(70.5,\n",
       "    205.02610778808594,\n",
       "    79.166015625,\n",
       "    217.02610778808594,\n",
       "    'A',\n",
       "    0,\n",
       "    0,\n",
       "    0),\n",
       "   (82.05670166015625,\n",
       "    205.02610778808594,\n",
       "    143.398681640625,\n",
       "    217.02610778808594,\n",
       "    'High-Level',\n",
       "    0,\n",
       "    0,\n",
       "    1),\n",
       "   (146.7366943359375,\n",
       "    205.02610778808594,\n",
       "    175.40652465820312,\n",
       "    217.02610778808594,\n",
       "    'Look',\n",
       "    0,\n",
       "    0,\n",
       "    2),\n",
       "   (70.5,\n",
       "    230.45704650878906,\n",
       "    89.34814453125,\n",
       "    239.45704650878906,\n",
       "    'Let’s',\n",
       "    1,\n",
       "    0,\n",
       "    0),\n",
       "   (91.85014343261719,\n",
       "    230.45704650878906,\n",
       "    113.86550903320312,\n",
       "    239.45704650878906,\n",
       "    'begin',\n",
       "    1,\n",
       "    0,\n",
       "    1),\n",
       "   (116.36613464355469,\n",
       "    230.45704650878906,\n",
       "    125.87013244628906,\n",
       "    239.45704650878906,\n",
       "    'by',\n",
       "    1,\n",
       "    0,\n",
       "    2),\n",
       "   (128.37213134765625,\n",
       "    230.45704650878906,\n",
       "    156.885498046875,\n",
       "    239.45704650878906,\n",
       "    'looking',\n",
       "    1,\n",
       "    0,\n",
       "    3),\n",
       "   (159.38612365722656,\n",
       "    230.45704650878906,\n",
       "    166.89060974121094,\n",
       "    239.45704650878906,\n",
       "    'at',\n",
       "    1,\n",
       "    0,\n",
       "    4),\n",
       "   (169.3941192626953,\n",
       "    230.45704650878906,\n",
       "    181.90548706054688,\n",
       "    239.45704650878906,\n",
       "    'the',\n",
       "    1,\n",
       "    0,\n",
       "    5),\n",
       "   (184.40611267089844,\n",
       "    230.45704650878906,\n",
       "    208.91461181640625,\n",
       "    239.45704650878906,\n",
       "    'model',\n",
       "    1,\n",
       "    0,\n",
       "    6),\n",
       "   (211.41510009765625,\n",
       "    230.45704650878906,\n",
       "    220.91909790039062,\n",
       "    239.45704650878906,\n",
       "    'as',\n",
       "    1,\n",
       "    0,\n",
       "    7),\n",
       "   (223.4210968017578,\n",
       "    230.45704650878906,\n",
       "    228.4264678955078,\n",
       "    239.45704650878906,\n",
       "    'a',\n",
       "    1,\n",
       "    0,\n",
       "    8),\n",
       "   (230.92709350585938,\n",
       "    230.45704650878906,\n",
       "    254.43646240234375,\n",
       "    239.45704650878906,\n",
       "    'single',\n",
       "    1,\n",
       "    0,\n",
       "    9),\n",
       "   (256.93707275390625,\n",
       "    230.45704650878906,\n",
       "    277.9430847167969,\n",
       "    239.45704650878906,\n",
       "    'black',\n",
       "    1,\n",
       "    0,\n",
       "    10),\n",
       "   (280.445068359375,\n",
       "    230.45704650878906,\n",
       "    297.4535827636719,\n",
       "    239.45704650878906,\n",
       "    'box.',\n",
       "    1,\n",
       "    0,\n",
       "    11),\n",
       "   (299.9571228027344,\n",
       "    230.45704650878906,\n",
       "    307.4645080566406,\n",
       "    239.45704650878906,\n",
       "    'In',\n",
       "    1,\n",
       "    0,\n",
       "    12),\n",
       "   (309.96514892578125,\n",
       "    230.45704650878906,\n",
       "    314.97052001953125,\n",
       "    239.45704650878906,\n",
       "    'a',\n",
       "    1,\n",
       "    0,\n",
       "    13),\n",
       "   (317.4711608886719,\n",
       "    230.45704650878906,\n",
       "    351.4835205078125,\n",
       "    239.45704650878906,\n",
       "    'machine',\n",
       "    1,\n",
       "    0,\n",
       "    14),\n",
       "   (353.9841613769531,\n",
       "    230.45704650878906,\n",
       "    395.5025329589844,\n",
       "    239.45704650878906,\n",
       "    'translation',\n",
       "    1,\n",
       "    0,\n",
       "    15),\n",
       "   (398.003173828125,\n",
       "    230.45704650878906,\n",
       "    443.52362060546875,\n",
       "    239.45704650878906,\n",
       "    'application,',\n",
       "    1,\n",
       "    0,\n",
       "    16),\n",
       "   (446.02716064453125,\n",
       "    230.45704650878906,\n",
       "    450.525634765625,\n",
       "    239.45704650878906,\n",
       "    'it',\n",
       "    1,\n",
       "    0,\n",
       "    17),\n",
       "   (453.0291748046875,\n",
       "    230.45704650878906,\n",
       "    476.53851318359375,\n",
       "    239.45704650878906,\n",
       "    'would',\n",
       "    1,\n",
       "    0,\n",
       "    18),\n",
       "   (479.0391540527344,\n",
       "    230.45704650878906,\n",
       "    496.050537109375,\n",
       "    239.45704650878906,\n",
       "    'take',\n",
       "    1,\n",
       "    0,\n",
       "    19),\n",
       "   (498.5511779785156,\n",
       "    230.45704650878906,\n",
       "    503.5565490722656,\n",
       "    239.45704650878906,\n",
       "    'a',\n",
       "    1,\n",
       "    0,\n",
       "    20),\n",
       "   (70.5,\n",
       "    242.95704650878906,\n",
       "    107.02336883544922,\n",
       "    251.95704650878906,\n",
       "    'sentence',\n",
       "    1,\n",
       "    1,\n",
       "    0),\n",
       "   (109.52399444580078,\n",
       "    242.95704650878906,\n",
       "    116.5273666381836,\n",
       "    251.95704650878906,\n",
       "    'in',\n",
       "    1,\n",
       "    1,\n",
       "    1),\n",
       "   (119.02799224853516,\n",
       "    242.95704650878906,\n",
       "    134.04135131835938,\n",
       "    251.95704650878906,\n",
       "    'one',\n",
       "    1,\n",
       "    1,\n",
       "    2),\n",
       "   (136.5419921875,\n",
       "    242.95704650878906,\n",
       "    176.06846618652344,\n",
       "    251.95704650878906,\n",
       "    'language,',\n",
       "    1,\n",
       "    1,\n",
       "    3),\n",
       "   (178.5719757080078,\n",
       "    242.95704650878906,\n",
       "    193.58534240722656,\n",
       "    251.95704650878906,\n",
       "    'and',\n",
       "    1,\n",
       "    1,\n",
       "    4),\n",
       "   (196.08596801757812,\n",
       "    242.95704650878906,\n",
       "    221.1044464111328,\n",
       "    251.95704650878906,\n",
       "    'output',\n",
       "    1,\n",
       "    1,\n",
       "    5),\n",
       "   (223.6079559326172,\n",
       "    242.95704650878906,\n",
       "    232.6079559326172,\n",
       "    251.95704650878906,\n",
       "    'its',\n",
       "    1,\n",
       "    1,\n",
       "    6),\n",
       "   (235.10995483398438,\n",
       "    242.95704650878906,\n",
       "    276.6282958984375,\n",
       "    251.95704650878906,\n",
       "    'translation',\n",
       "    1,\n",
       "    1,\n",
       "    7),\n",
       "   (279.1289367675781,\n",
       "    242.95704650878906,\n",
       "    286.13232421875,\n",
       "    251.95704650878906,\n",
       "    'in',\n",
       "    1,\n",
       "    1,\n",
       "    8),\n",
       "   (288.6329650878906,\n",
       "    242.95704650878906,\n",
       "    321.18603515625,\n",
       "    251.95704650878906,\n",
       "    'another.',\n",
       "    1,\n",
       "    1,\n",
       "    9),\n",
       "   (70.5, 395.95703125, 103.52236938476562, 404.95703125, 'Popping', 2, 0, 0),\n",
       "   (106.02299499511719,\n",
       "    395.95703125,\n",
       "    126.04035949707031,\n",
       "    404.95703125,\n",
       "    'open',\n",
       "    2,\n",
       "    0,\n",
       "    1),\n",
       "   (128.54098510742188,\n",
       "    395.95703125,\n",
       "    143.5514678955078,\n",
       "    404.95703125,\n",
       "    'that',\n",
       "    2,\n",
       "    0,\n",
       "    2),\n",
       "   (146.0549774169922,\n",
       "    395.95703125,\n",
       "    179.5619659423828,\n",
       "    404.95703125,\n",
       "    'Optimus',\n",
       "    2,\n",
       "    0,\n",
       "    3),\n",
       "   (182.06396484375,\n",
       "    395.95703125,\n",
       "    205.5643310546875,\n",
       "    404.95703125,\n",
       "    'Prime',\n",
       "    2,\n",
       "    0,\n",
       "    4),\n",
       "   (208.06495666503906,\n",
       "    395.95703125,\n",
       "    249.5894317626953,\n",
       "    404.95703125,\n",
       "    'goodness,',\n",
       "    2,\n",
       "    0,\n",
       "    5),\n",
       "   (252.0929412841797,\n",
       "    395.95703125,\n",
       "    263.5963134765625,\n",
       "    404.95703125,\n",
       "    'we',\n",
       "    2,\n",
       "    0,\n",
       "    6),\n",
       "   (266.096923828125,\n",
       "    395.95703125,\n",
       "    280.6063232421875,\n",
       "    404.95703125,\n",
       "    'see',\n",
       "    2,\n",
       "    0,\n",
       "    7),\n",
       "   (283.10693359375,\n",
       "    395.95703125,\n",
       "    293.1163024902344,\n",
       "    404.95703125,\n",
       "    'an',\n",
       "    2,\n",
       "    0,\n",
       "    8),\n",
       "   (295.616943359375,\n",
       "    395.95703125,\n",
       "    332.1402893066406,\n",
       "    404.95703125,\n",
       "    'encoding',\n",
       "    2,\n",
       "    0,\n",
       "    9),\n",
       "   (334.64093017578125,\n",
       "    395.95703125,\n",
       "    381.6644287109375,\n",
       "    404.95703125,\n",
       "    'component,',\n",
       "    2,\n",
       "    0,\n",
       "    10),\n",
       "   (384.16796875, 395.95703125, 389.17333984375, 404.95703125, 'a', 2, 0, 11),\n",
       "   (391.6739807128906,\n",
       "    395.95703125,\n",
       "    428.19732666015625,\n",
       "    404.95703125,\n",
       "    'decoding',\n",
       "    2,\n",
       "    0,\n",
       "    12),\n",
       "   (430.6979675292969,\n",
       "    395.95703125,\n",
       "    477.7214660644531,\n",
       "    404.95703125,\n",
       "    'component,',\n",
       "    2,\n",
       "    0,\n",
       "    13),\n",
       "   (480.2250061035156,\n",
       "    395.95703125,\n",
       "    495.2383728027344,\n",
       "    404.95703125,\n",
       "    'and',\n",
       "    2,\n",
       "    0,\n",
       "    14),\n",
       "   (70.5,\n",
       "    408.45703125,\n",
       "    118.52400207519531,\n",
       "    417.45703125,\n",
       "    'connections',\n",
       "    2,\n",
       "    1,\n",
       "    0),\n",
       "   (121.0260009765625,\n",
       "    408.45703125,\n",
       "    155.04736328125,\n",
       "    417.45703125,\n",
       "    'between',\n",
       "    2,\n",
       "    1,\n",
       "    1),\n",
       "   (157.54798889160156,\n",
       "    408.45703125,\n",
       "    180.0554656982422,\n",
       "    417.45703125,\n",
       "    'them.',\n",
       "    2,\n",
       "    1,\n",
       "    2),\n",
       "   (70.5, 675.95703125, 86.00837707519531, 684.95703125, 'The', 3, 0, 0),\n",
       "   (88.50900268554688,\n",
       "    675.95703125,\n",
       "    125.03236389160156,\n",
       "    684.95703125,\n",
       "    'encoding',\n",
       "    3,\n",
       "    0,\n",
       "    1),\n",
       "   (127.53298950195312,\n",
       "    675.95703125,\n",
       "    172.05447387695312,\n",
       "    684.95703125,\n",
       "    'component',\n",
       "    3,\n",
       "    0,\n",
       "    2),\n",
       "   (174.5579833984375,\n",
       "    675.95703125,\n",
       "    181.0559844970703,\n",
       "    684.95703125,\n",
       "    'is',\n",
       "    3,\n",
       "    0,\n",
       "    3),\n",
       "   (183.5579833984375,\n",
       "    675.95703125,\n",
       "    188.5633544921875,\n",
       "    684.95703125,\n",
       "    'a',\n",
       "    3,\n",
       "    0,\n",
       "    4),\n",
       "   (191.06398010253906,\n",
       "    675.95703125,\n",
       "    212.06997680664062,\n",
       "    684.95703125,\n",
       "    'stack',\n",
       "    3,\n",
       "    0,\n",
       "    5),\n",
       "   (214.5719757080078,\n",
       "    675.95703125,\n",
       "    222.0764617919922,\n",
       "    684.95703125,\n",
       "    'of',\n",
       "    3,\n",
       "    0,\n",
       "    6),\n",
       "   (224.57997131347656,\n",
       "    675.95703125,\n",
       "    261.5969543457031,\n",
       "    684.95703125,\n",
       "    'encoders',\n",
       "    3,\n",
       "    0,\n",
       "    7),\n",
       "   (264.09893798828125,\n",
       "    675.95703125,\n",
       "    279.6072998046875,\n",
       "    684.95703125,\n",
       "    '(the',\n",
       "    3,\n",
       "    0,\n",
       "    8),\n",
       "   (282.1079406738281,\n",
       "    675.95703125,\n",
       "    305.1210021972656,\n",
       "    684.95703125,\n",
       "    'paper',\n",
       "    3,\n",
       "    0,\n",
       "    9),\n",
       "   (307.6229553222656,\n",
       "    675.95703125,\n",
       "    333.12896728515625,\n",
       "    684.95703125,\n",
       "    'stacks',\n",
       "    3,\n",
       "    0,\n",
       "    10),\n",
       "   (335.6309814453125,\n",
       "    675.95703125,\n",
       "    346.62896728515625,\n",
       "    684.95703125,\n",
       "    'six',\n",
       "    3,\n",
       "    0,\n",
       "    11),\n",
       "   (349.1309814453125,\n",
       "    675.95703125,\n",
       "    356.6354675292969,\n",
       "    684.95703125,\n",
       "    'of',\n",
       "    3,\n",
       "    0,\n",
       "    12),\n",
       "   (359.1390075683594,\n",
       "    675.95703125,\n",
       "    379.1460876464844,\n",
       "    684.95703125,\n",
       "    'them',\n",
       "    3,\n",
       "    0,\n",
       "    13),\n",
       "   (381.6480407714844,\n",
       "    675.95703125,\n",
       "    391.65740966796875,\n",
       "    684.95703125,\n",
       "    'on',\n",
       "    3,\n",
       "    0,\n",
       "    14),\n",
       "   (394.1580505371094,\n",
       "    675.95703125,\n",
       "    406.66943359375,\n",
       "    684.95703125,\n",
       "    'top',\n",
       "    3,\n",
       "    0,\n",
       "    15),\n",
       "   (409.1700744628906,\n",
       "    675.95703125,\n",
       "    416.674560546875,\n",
       "    684.95703125,\n",
       "    'of',\n",
       "    3,\n",
       "    0,\n",
       "    16),\n",
       "   (419.1781005859375,\n",
       "    675.95703125,\n",
       "    438.69146728515625,\n",
       "    684.95703125,\n",
       "    'each',\n",
       "    3,\n",
       "    0,\n",
       "    17),\n",
       "   (441.1921081542969,\n",
       "    675.95703125,\n",
       "    461.70318603515625,\n",
       "    684.95703125,\n",
       "    'other',\n",
       "    3,\n",
       "    0,\n",
       "    18),\n",
       "   (464.20513916015625,\n",
       "    675.95703125,\n",
       "    469.21051025390625,\n",
       "    684.95703125,\n",
       "    '–',\n",
       "    3,\n",
       "    0,\n",
       "    19),\n",
       "   (471.7111511230469,\n",
       "    675.95703125,\n",
       "    498.580078125,\n",
       "    684.95703125,\n",
       "    'there’s',\n",
       "    3,\n",
       "    0,\n",
       "    20),\n",
       "   (501.08209228515625,\n",
       "    675.95703125,\n",
       "    530.6034545898438,\n",
       "    684.95703125,\n",
       "    'nothing',\n",
       "    3,\n",
       "    0,\n",
       "    21),\n",
       "   (70.5, 688.45703125, 101.50651550292969, 697.45703125, 'magical', 3, 1, 0),\n",
       "   (104.00700378417969,\n",
       "    688.45703125,\n",
       "    126.52348327636719,\n",
       "    697.45703125,\n",
       "    'about',\n",
       "    3,\n",
       "    1,\n",
       "    1),\n",
       "   (129.02699279785156,\n",
       "    688.45703125,\n",
       "    141.53836059570312,\n",
       "    697.45703125,\n",
       "    'the',\n",
       "    3,\n",
       "    1,\n",
       "    2),\n",
       "   (144.0389862060547,\n",
       "    688.45703125,\n",
       "    174.54904174804688,\n",
       "    697.45703125,\n",
       "    'number',\n",
       "    3,\n",
       "    1,\n",
       "    3),\n",
       "   (177.05096435546875,\n",
       "    688.45703125,\n",
       "    190.54945373535156,\n",
       "    697.45703125,\n",
       "    'six,',\n",
       "    3,\n",
       "    1,\n",
       "    4),\n",
       "   (193.05296325683594,\n",
       "    688.45703125,\n",
       "    208.0663299560547,\n",
       "    697.45703125,\n",
       "    'one',\n",
       "    3,\n",
       "    1,\n",
       "    5),\n",
       "   (210.56695556640625,\n",
       "    688.45703125,\n",
       "    225.07632446289062,\n",
       "    697.45703125,\n",
       "    'can',\n",
       "    3,\n",
       "    1,\n",
       "    6),\n",
       "   (227.5769500732422,\n",
       "    688.45703125,\n",
       "    263.0909423828125,\n",
       "    697.45703125,\n",
       "    'definitely',\n",
       "    3,\n",
       "    1,\n",
       "    7),\n",
       "   (265.59295654296875,\n",
       "    688.45703125,\n",
       "    310.1054382324219,\n",
       "    697.45703125,\n",
       "    'experiment',\n",
       "    3,\n",
       "    1,\n",
       "    8),\n",
       "   (312.6089782714844,\n",
       "    688.45703125,\n",
       "    328.6123352050781,\n",
       "    697.45703125,\n",
       "    'with',\n",
       "    3,\n",
       "    1,\n",
       "    9),\n",
       "   (331.11297607421875,\n",
       "    688.45703125,\n",
       "    351.6240539550781,\n",
       "    697.45703125,\n",
       "    'other',\n",
       "    3,\n",
       "    1,\n",
       "    10),\n",
       "   (354.1260070800781,\n",
       "    688.45703125,\n",
       "    415.14453125,\n",
       "    697.45703125,\n",
       "    'arrangements).',\n",
       "    3,\n",
       "    1,\n",
       "    11),\n",
       "   (417.5185546875,\n",
       "    688.45703125,\n",
       "    433.02691650390625,\n",
       "    697.45703125,\n",
       "    'The',\n",
       "    3,\n",
       "    1,\n",
       "    12),\n",
       "   (435.5275573730469,\n",
       "    688.45703125,\n",
       "    472.0509033203125,\n",
       "    697.45703125,\n",
       "    'decoding',\n",
       "    3,\n",
       "    1,\n",
       "    13),\n",
       "   (474.5515441894531,\n",
       "    688.45703125,\n",
       "    519.072998046875,\n",
       "    697.45703125,\n",
       "    'component',\n",
       "    3,\n",
       "    1,\n",
       "    14),\n",
       "   (521.5765380859375,\n",
       "    688.45703125,\n",
       "    528.0745849609375,\n",
       "    697.45703125,\n",
       "    'is',\n",
       "    3,\n",
       "    1,\n",
       "    15),\n",
       "   (530.5765380859375,\n",
       "    688.45703125,\n",
       "    535.5819091796875,\n",
       "    697.45703125,\n",
       "    'a',\n",
       "    3,\n",
       "    1,\n",
       "    16),\n",
       "   (70.5, 700.95703125, 91.50599670410156, 709.95703125, 'stack', 3, 2, 0),\n",
       "   (94.00800323486328,\n",
       "    700.95703125,\n",
       "    101.51248931884766,\n",
       "    709.95703125,\n",
       "    'of',\n",
       "    3,\n",
       "    2,\n",
       "    1),\n",
       "   (104.01599884033203,\n",
       "    700.95703125,\n",
       "    141.03298950195312,\n",
       "    709.95703125,\n",
       "    'decoders',\n",
       "    3,\n",
       "    2,\n",
       "    2),\n",
       "   (143.5349884033203,\n",
       "    700.95703125,\n",
       "    151.0394744873047,\n",
       "    709.95703125,\n",
       "    'of',\n",
       "    3,\n",
       "    2,\n",
       "    3),\n",
       "   (153.54298400878906,\n",
       "    700.95703125,\n",
       "    166.05435180664062,\n",
       "    709.95703125,\n",
       "    'the',\n",
       "    3,\n",
       "    2,\n",
       "    4),\n",
       "   (168.5549774169922,\n",
       "    700.95703125,\n",
       "    190.56134033203125,\n",
       "    709.95703125,\n",
       "    'same',\n",
       "    3,\n",
       "    2,\n",
       "    5),\n",
       "   (193.0619659423828,\n",
       "    700.95703125,\n",
       "    225.5830078125,\n",
       "    709.95703125,\n",
       "    'number.',\n",
       "    3,\n",
       "    2,\n",
       "    6)]},\n",
       " {'metadata': {'format': 'PDF 1.4',\n",
       "   'title': 'The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',\n",
       "   'producer': 'Skia/PDF m124',\n",
       "   'creationDate': \"D:20240501121657+00'00'\",\n",
       "   'modDate': \"D:20240501121657+00'00'\",\n",
       "   'trapped': '',\n",
       "   'encryption': None,\n",
       "   'file_path': 'D:\\\\ML\\\\Langgraph-end-to-end\\\\The Illustrated Transformer.pdf',\n",
       "   'page_count': 23,\n",
       "   'page': 3},\n",
       "  'toc_items': [],\n",
       "  'tables': [],\n",
       "  'images': [{'number': 0,\n",
       "    'bbox': Rect(70.75, 50.0, 540.75, 333.7498779296875),\n",
       "    'transform': (470.0000305175781,\n",
       "     0.0,\n",
       "     -0.0,\n",
       "     306.0,\n",
       "     70.75,\n",
       "     27.7498779296875),\n",
       "    'width': 1218,\n",
       "    'height': 793,\n",
       "    'colorspace': 3,\n",
       "    'cs-name': 'ICCBased(RGB,Google/Skia/3C3AA278A22CB84C7D076EDD085A2143)',\n",
       "    'xres': 96,\n",
       "    'yres': 96,\n",
       "    'bpc': 8,\n",
       "    'size': 229530},\n",
       "   {'number': 2,\n",
       "    'bbox': Rect(107.75000762939453, 376.74993896484375, 503.7500305175781, 582.2499389648438),\n",
       "    'transform': (396.0000305175781,\n",
       "     0.0,\n",
       "     -0.0,\n",
       "     205.50001525878906,\n",
       "     107.75000762939453,\n",
       "     376.74993896484375),\n",
       "    'width': 792,\n",
       "    'height': 411,\n",
       "    'colorspace': 3,\n",
       "    'cs-name': 'ICCBased(RGB,Google/Skia/3C3AA278A22CB84C7D076EDD085A2143)',\n",
       "    'xres': 96,\n",
       "    'yres': 96,\n",
       "    'bpc': 8,\n",
       "    'size': 50304}],\n",
       "  'graphics': [],\n",
       "  'text': 'The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sublayers:\\n\\nThe encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the\\ninput sentence as it encodes a specific word. We’ll look closer at self-attention later in the post.\\n\\nThe outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network\\nis independently applied to each position.\\n\\nThe decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant\\n[parts of the input sentence (similar what attention does in seq2seq models (https://jalammar.github.io/visualizing-](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\\n[neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)).](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\\n\\n\\n-----\\n\\n',\n",
       "  'words': [(70.5,\n",
       "    345.45703125,\n",
       "    86.00837707519531,\n",
       "    354.45703125,\n",
       "    'The',\n",
       "    0,\n",
       "    0,\n",
       "    0),\n",
       "   (88.50900268554688,\n",
       "    345.45703125,\n",
       "    125.52599334716797,\n",
       "    354.45703125,\n",
       "    'encoders',\n",
       "    0,\n",
       "    0,\n",
       "    1),\n",
       "   (128.02798461914062,\n",
       "    345.45703125,\n",
       "    141.03436279296875,\n",
       "    354.45703125,\n",
       "    'are',\n",
       "    0,\n",
       "    0,\n",
       "    2),\n",
       "   (143.5349884033203,\n",
       "    345.45703125,\n",
       "    152.5364990234375,\n",
       "    354.45703125,\n",
       "    'all',\n",
       "    0,\n",
       "    0,\n",
       "    3),\n",
       "   (155.0369873046875,\n",
       "    345.45703125,\n",
       "    188.0504913330078,\n",
       "    354.45703125,\n",
       "    'identical',\n",
       "    0,\n",
       "    0,\n",
       "    4),\n",
       "   (190.5509796142578,\n",
       "    345.45703125,\n",
       "    197.55435180664062,\n",
       "    354.45703125,\n",
       "    'in',\n",
       "    0,\n",
       "    0,\n",
       "    5),\n",
       "   (200.0549774169922,\n",
       "    345.45703125,\n",
       "    235.0663299560547,\n",
       "    354.45703125,\n",
       "    'structure',\n",
       "    0,\n",
       "    0,\n",
       "    6),\n",
       "   (237.56695556640625,\n",
       "    345.45703125,\n",
       "    252.5684356689453,\n",
       "    354.45703125,\n",
       "    '(yet',\n",
       "    0,\n",
       "    0,\n",
       "    7),\n",
       "   (255.0719451904297,\n",
       "    345.45703125,\n",
       "    272.0819396972656,\n",
       "    354.45703125,\n",
       "    'they',\n",
       "    0,\n",
       "    0,\n",
       "    8),\n",
       "   (274.58392333984375,\n",
       "    345.45703125,\n",
       "    284.59332275390625,\n",
       "    354.45703125,\n",
       "    'do',\n",
       "    0,\n",
       "    0,\n",
       "    9),\n",
       "   (287.0939636230469,\n",
       "    345.45703125,\n",
       "    299.6024475097656,\n",
       "    354.45703125,\n",
       "    'not',\n",
       "    0,\n",
       "    0,\n",
       "    10),\n",
       "   (302.1059875488281,\n",
       "    345.45703125,\n",
       "    324.6163635253906,\n",
       "    354.45703125,\n",
       "    'share',\n",
       "    0,\n",
       "    0,\n",
       "    11),\n",
       "   (327.11700439453125,\n",
       "    345.45703125,\n",
       "    363.1244812011719,\n",
       "    354.45703125,\n",
       "    'weights).',\n",
       "    0,\n",
       "    0,\n",
       "    12),\n",
       "   (365.6280212402344,\n",
       "    345.45703125,\n",
       "    386.140380859375,\n",
       "    354.45703125,\n",
       "    'Each',\n",
       "    0,\n",
       "    0,\n",
       "    13),\n",
       "   (388.6410217285156,\n",
       "    345.45703125,\n",
       "    403.6543884277344,\n",
       "    354.45703125,\n",
       "    'one',\n",
       "    0,\n",
       "    0,\n",
       "    14),\n",
       "   (406.155029296875,\n",
       "    345.45703125,\n",
       "    412.65301513671875,\n",
       "    354.45703125,\n",
       "    'is',\n",
       "    0,\n",
       "    0,\n",
       "    15),\n",
       "   (415.155029296875,\n",
       "    345.45703125,\n",
       "    442.6694030761719,\n",
       "    354.45703125,\n",
       "    'broken',\n",
       "    0,\n",
       "    0,\n",
       "    16),\n",
       "   (445.1700439453125,\n",
       "    345.45703125,\n",
       "    466.681396484375,\n",
       "    354.45703125,\n",
       "    'down',\n",
       "    0,\n",
       "    0,\n",
       "    17),\n",
       "   (469.1820373535156,\n",
       "    345.45703125,\n",
       "    483.69140625,\n",
       "    354.45703125,\n",
       "    'into',\n",
       "    0,\n",
       "    0,\n",
       "    18),\n",
       "   (486.1920471191406,\n",
       "    345.45703125,\n",
       "    500.1974182128906,\n",
       "    354.45703125,\n",
       "    'two',\n",
       "    0,\n",
       "    0,\n",
       "    19),\n",
       "   (502.69805908203125,\n",
       "    345.45703125,\n",
       "    520.203125,\n",
       "    354.45703125,\n",
       "    'sub-',\n",
       "    0,\n",
       "    0,\n",
       "    20),\n",
       "   (70.5, 358.45703125, 97.00349426269531, 367.45703125, 'layers:', 0, 1, 0),\n",
       "   (70.5, 593.95703125, 86.00837707519531, 602.95703125, 'The', 1, 0, 0),\n",
       "   (88.50900268554688,\n",
       "    593.95703125,\n",
       "    127.70361328125,\n",
       "    602.95703125,\n",
       "    'encoder’s',\n",
       "    1,\n",
       "    0,\n",
       "    1),\n",
       "   (130.2056121826172,\n",
       "    593.95703125,\n",
       "    154.2176055908203,\n",
       "    602.95703125,\n",
       "    'inputs',\n",
       "    1,\n",
       "    0,\n",
       "    2),\n",
       "   (156.7196044921875,\n",
       "    593.95703125,\n",
       "    171.2170867919922,\n",
       "    602.95703125,\n",
       "    'first',\n",
       "    1,\n",
       "    0,\n",
       "    3),\n",
       "   (173.72059631347656,\n",
       "    593.95703125,\n",
       "    189.72410583496094,\n",
       "    602.95703125,\n",
       "    'flow',\n",
       "    1,\n",
       "    0,\n",
       "    4),\n",
       "   (192.22459411621094,\n",
       "    593.95703125,\n",
       "    222.7449493408203,\n",
       "    602.95703125,\n",
       "    'through',\n",
       "    1,\n",
       "    0,\n",
       "    5),\n",
       "   (225.24557495117188,\n",
       "    593.95703125,\n",
       "    230.25094604492188,\n",
       "    602.95703125,\n",
       "    'a',\n",
       "    1,\n",
       "    0,\n",
       "    6),\n",
       "   (232.75157165527344,\n",
       "    593.95703125,\n",
       "    284.2779235839844,\n",
       "    602.95703125,\n",
       "    'self-attention',\n",
       "    1,\n",
       "    0,\n",
       "    7),\n",
       "   (286.778564453125,\n",
       "    593.95703125,\n",
       "    306.2816162109375,\n",
       "    602.95703125,\n",
       "    'layer',\n",
       "    1,\n",
       "    0,\n",
       "    8),\n",
       "   (308.7835693359375,\n",
       "    593.95703125,\n",
       "    313.7889404296875,\n",
       "    602.95703125,\n",
       "    '–',\n",
       "    1,\n",
       "    0,\n",
       "    9),\n",
       "   (316.2895812988281,\n",
       "    593.95703125,\n",
       "    321.2949523925781,\n",
       "    602.95703125,\n",
       "    'a',\n",
       "    1,\n",
       "    0,\n",
       "    10),\n",
       "   (323.79559326171875,\n",
       "    593.95703125,\n",
       "    343.29864501953125,\n",
       "    602.95703125,\n",
       "    'layer',\n",
       "    1,\n",
       "    0,\n",
       "    11),\n",
       "   (345.80059814453125,\n",
       "    593.95703125,\n",
       "    360.81109619140625,\n",
       "    602.95703125,\n",
       "    'that',\n",
       "    1,\n",
       "    0,\n",
       "    12),\n",
       "   (363.31463623046875,\n",
       "    593.95703125,\n",
       "    384.8246154785156,\n",
       "    602.95703125,\n",
       "    'helps',\n",
       "    1,\n",
       "    0,\n",
       "    13),\n",
       "   (387.3266296386719,\n",
       "    593.95703125,\n",
       "    399.8380126953125,\n",
       "    602.95703125,\n",
       "    'the',\n",
       "    1,\n",
       "    0,\n",
       "    14),\n",
       "   (402.3386535644531,\n",
       "    593.95703125,\n",
       "    434.855712890625,\n",
       "    602.95703125,\n",
       "    'encoder',\n",
       "    1,\n",
       "    0,\n",
       "    15),\n",
       "   (437.357666015625,\n",
       "    593.95703125,\n",
       "    453.8636474609375,\n",
       "    602.95703125,\n",
       "    'look',\n",
       "    1,\n",
       "    0,\n",
       "    16),\n",
       "   (456.36566162109375,\n",
       "    593.95703125,\n",
       "    463.8701477050781,\n",
       "    602.95703125,\n",
       "    'at',\n",
       "    1,\n",
       "    0,\n",
       "    17),\n",
       "   (466.3736877441406,\n",
       "    593.95703125,\n",
       "    486.884765625,\n",
       "    602.95703125,\n",
       "    'other',\n",
       "    1,\n",
       "    0,\n",
       "    18),\n",
       "   (489.38671875,\n",
       "    593.95703125,\n",
       "    513.3897094726562,\n",
       "    602.95703125,\n",
       "    'words',\n",
       "    1,\n",
       "    0,\n",
       "    19),\n",
       "   (515.8917236328125,\n",
       "    593.95703125,\n",
       "    522.8950805664062,\n",
       "    602.95703125,\n",
       "    'in',\n",
       "    1,\n",
       "    0,\n",
       "    20),\n",
       "   (525.395751953125,\n",
       "    593.95703125,\n",
       "    537.9071044921875,\n",
       "    602.95703125,\n",
       "    'the',\n",
       "    1,\n",
       "    0,\n",
       "    21),\n",
       "   (70.5, 606.45703125, 90.010498046875, 615.45703125, 'input', 1, 1, 0),\n",
       "   (92.51400756835938,\n",
       "    606.45703125,\n",
       "    129.03736877441406,\n",
       "    615.45703125,\n",
       "    'sentence',\n",
       "    1,\n",
       "    1,\n",
       "    1),\n",
       "   (131.53799438476562,\n",
       "    606.45703125,\n",
       "    141.0419921875,\n",
       "    615.45703125,\n",
       "    'as',\n",
       "    1,\n",
       "    1,\n",
       "    2),\n",
       "   (143.5439910888672,\n",
       "    606.45703125,\n",
       "    148.04248046875,\n",
       "    615.45703125,\n",
       "    'it',\n",
       "    1,\n",
       "    1,\n",
       "    3),\n",
       "   (150.54598999023438,\n",
       "    606.45703125,\n",
       "    184.56597900390625,\n",
       "    615.45703125,\n",
       "    'encodes',\n",
       "    1,\n",
       "    1,\n",
       "    4),\n",
       "   (187.06797790527344,\n",
       "    606.45703125,\n",
       "    192.07334899902344,\n",
       "    615.45703125,\n",
       "    'a',\n",
       "    1,\n",
       "    1,\n",
       "    5),\n",
       "   (194.573974609375,\n",
       "    606.45703125,\n",
       "    224.57997131347656,\n",
       "    615.45703125,\n",
       "    'specific',\n",
       "    1,\n",
       "    1,\n",
       "    6),\n",
       "   (227.08197021484375,\n",
       "    606.45703125,\n",
       "    249.08544921875,\n",
       "    615.45703125,\n",
       "    'word.',\n",
       "    1,\n",
       "    1,\n",
       "    7),\n",
       "   (251.58895874023438,\n",
       "    606.45703125,\n",
       "    270.9345703125,\n",
       "    615.45703125,\n",
       "    'We’ll',\n",
       "    1,\n",
       "    1,\n",
       "    8),\n",
       "   (273.43505859375,\n",
       "    606.45703125,\n",
       "    289.9410705566406,\n",
       "    615.45703125,\n",
       "    'look',\n",
       "    1,\n",
       "    1,\n",
       "    9),\n",
       "   (292.4430847167969,\n",
       "    606.45703125,\n",
       "    316.4461364746094,\n",
       "    615.45703125,\n",
       "    'closer',\n",
       "    1,\n",
       "    1,\n",
       "    10),\n",
       "   (318.9480895996094,\n",
       "    606.45703125,\n",
       "    326.45257568359375,\n",
       "    615.45703125,\n",
       "    'at',\n",
       "    1,\n",
       "    1,\n",
       "    11),\n",
       "   (328.95611572265625,\n",
       "    606.45703125,\n",
       "    380.4825134277344,\n",
       "    615.45703125,\n",
       "    'self-attention',\n",
       "    1,\n",
       "    1,\n",
       "    12),\n",
       "   (382.983154296875,\n",
       "    606.45703125,\n",
       "    400.48822021484375,\n",
       "    615.45703125,\n",
       "    'later',\n",
       "    1,\n",
       "    1,\n",
       "    13),\n",
       "   (402.99017333984375,\n",
       "    606.45703125,\n",
       "    409.9935302734375,\n",
       "    615.45703125,\n",
       "    'in',\n",
       "    1,\n",
       "    1,\n",
       "    14),\n",
       "   (412.4941711425781,\n",
       "    606.45703125,\n",
       "    425.00555419921875,\n",
       "    615.45703125,\n",
       "    'the',\n",
       "    1,\n",
       "    1,\n",
       "    15),\n",
       "   (427.5061950683594,\n",
       "    606.45703125,\n",
       "    447.0166931152344,\n",
       "    615.45703125,\n",
       "    'post.',\n",
       "    1,\n",
       "    1,\n",
       "    16),\n",
       "   (70.5, 626.95703125, 86.00837707519531, 635.95703125, 'The', 2, 0, 0),\n",
       "   (88.50900268554688,\n",
       "    626.95703125,\n",
       "    118.02899169921875,\n",
       "    635.95703125,\n",
       "    'outputs',\n",
       "    2,\n",
       "    0,\n",
       "    1),\n",
       "   (120.53099060058594,\n",
       "    626.95703125,\n",
       "    128.0354766845703,\n",
       "    635.95703125,\n",
       "    'of',\n",
       "    2,\n",
       "    0,\n",
       "    2),\n",
       "   (130.5389862060547,\n",
       "    626.95703125,\n",
       "    143.05035400390625,\n",
       "    635.95703125,\n",
       "    'the',\n",
       "    2,\n",
       "    0,\n",
       "    3),\n",
       "   (145.5509796142578,\n",
       "    626.95703125,\n",
       "    197.07733154296875,\n",
       "    635.95703125,\n",
       "    'self-attention',\n",
       "    2,\n",
       "    0,\n",
       "    4),\n",
       "   (199.5779571533203,\n",
       "    626.95703125,\n",
       "    219.08102416992188,\n",
       "    635.95703125,\n",
       "    'layer',\n",
       "    2,\n",
       "    0,\n",
       "    5),\n",
       "   (221.58294677734375,\n",
       "    626.95703125,\n",
       "    234.5893096923828,\n",
       "    635.95703125,\n",
       "    'are',\n",
       "    2,\n",
       "    0,\n",
       "    6),\n",
       "   (237.08993530273438,\n",
       "    626.95703125,\n",
       "    249.60130310058594,\n",
       "    635.95703125,\n",
       "    'fed',\n",
       "    2,\n",
       "    0,\n",
       "    7),\n",
       "   (252.1019287109375,\n",
       "    626.95703125,\n",
       "    259.60931396484375,\n",
       "    635.95703125,\n",
       "    'to',\n",
       "    2,\n",
       "    0,\n",
       "    8),\n",
       "   (262.10992431640625,\n",
       "    626.95703125,\n",
       "    267.11529541015625,\n",
       "    635.95703125,\n",
       "    'a',\n",
       "    2,\n",
       "    0,\n",
       "    9),\n",
       "   (269.61590576171875,\n",
       "    626.95703125,\n",
       "    320.1343078613281,\n",
       "    635.95703125,\n",
       "    'feed-forward',\n",
       "    2,\n",
       "    0,\n",
       "    10),\n",
       "   (322.63494873046875,\n",
       "    626.95703125,\n",
       "    347.6474609375,\n",
       "    635.95703125,\n",
       "    'neural',\n",
       "    2,\n",
       "    0,\n",
       "    11),\n",
       "   (350.14794921875,\n",
       "    626.95703125,\n",
       "    384.1574401855469,\n",
       "    635.95703125,\n",
       "    'network.',\n",
       "    2,\n",
       "    0,\n",
       "    12),\n",
       "   (386.51513671875,\n",
       "    626.95703125,\n",
       "    402.02349853515625,\n",
       "    635.95703125,\n",
       "    'The',\n",
       "    2,\n",
       "    0,\n",
       "    13),\n",
       "   (404.5241394042969,\n",
       "    626.95703125,\n",
       "    426.0326232910156,\n",
       "    635.95703125,\n",
       "    'exact',\n",
       "    2,\n",
       "    0,\n",
       "    14),\n",
       "   (428.5361633300781,\n",
       "    626.95703125,\n",
       "    450.54254150390625,\n",
       "    635.95703125,\n",
       "    'same',\n",
       "    2,\n",
       "    0,\n",
       "    15),\n",
       "   (453.0431823730469,\n",
       "    626.95703125,\n",
       "    503.56158447265625,\n",
       "    635.95703125,\n",
       "    'feed-forward',\n",
       "    2,\n",
       "    0,\n",
       "    16),\n",
       "   (506.0622253417969,\n",
       "    626.95703125,\n",
       "    537.5712280273438,\n",
       "    635.95703125,\n",
       "    'network',\n",
       "    2,\n",
       "    0,\n",
       "    17),\n",
       "   (70.5, 639.45703125, 76.99800109863281, 648.45703125, 'is', 2, 1, 0),\n",
       "   (79.5,\n",
       "    639.45703125,\n",
       "    135.53399658203125,\n",
       "    648.45703125,\n",
       "    'independently',\n",
       "    2,\n",
       "    1,\n",
       "    1),\n",
       "   (138.03598022460938,\n",
       "    639.45703125,\n",
       "    167.0533447265625,\n",
       "    648.45703125,\n",
       "    'applied',\n",
       "    2,\n",
       "    1,\n",
       "    2),\n",
       "   (169.55397033691406,\n",
       "    639.45703125,\n",
       "    177.06134033203125,\n",
       "    648.45703125,\n",
       "    'to',\n",
       "    2,\n",
       "    1,\n",
       "    3),\n",
       "   (179.5619659423828,\n",
       "    639.45703125,\n",
       "    199.07533264160156,\n",
       "    648.45703125,\n",
       "    'each',\n",
       "    2,\n",
       "    1,\n",
       "    4),\n",
       "   (201.57595825195312,\n",
       "    639.45703125,\n",
       "    235.09043884277344,\n",
       "    648.45703125,\n",
       "    'position.',\n",
       "    2,\n",
       "    1,\n",
       "    5),\n",
       "   (70.5, 659.45703125, 86.00837707519531, 668.45703125, 'The', 3, 0, 0),\n",
       "   (88.50900268554688,\n",
       "    659.45703125,\n",
       "    121.02606201171875,\n",
       "    668.45703125,\n",
       "    'decoder',\n",
       "    3,\n",
       "    0,\n",
       "    1),\n",
       "   (123.52799224853516,\n",
       "    659.45703125,\n",
       "    138.03598022460938,\n",
       "    668.45703125,\n",
       "    'has',\n",
       "    3,\n",
       "    0,\n",
       "    2),\n",
       "   (140.53799438476562,\n",
       "    659.45703125,\n",
       "    158.0533447265625,\n",
       "    668.45703125,\n",
       "    'both',\n",
       "    3,\n",
       "    0,\n",
       "    3),\n",
       "   (160.55398559570312,\n",
       "    659.45703125,\n",
       "    182.56935119628906,\n",
       "    668.45703125,\n",
       "    'those',\n",
       "    3,\n",
       "    0,\n",
       "    4),\n",
       "   (185.06997680664062,\n",
       "    659.45703125,\n",
       "    211.57345581054688,\n",
       "    668.45703125,\n",
       "    'layers,',\n",
       "    3,\n",
       "    0,\n",
       "    5),\n",
       "   (214.07696533203125,\n",
       "    659.45703125,\n",
       "    226.58544921875,\n",
       "    668.45703125,\n",
       "    'but',\n",
       "    3,\n",
       "    0,\n",
       "    6),\n",
       "   (229.08895874023438,\n",
       "    659.45703125,\n",
       "    263.1103210449219,\n",
       "    668.45703125,\n",
       "    'between',\n",
       "    3,\n",
       "    0,\n",
       "    7),\n",
       "   (265.6109619140625,\n",
       "    659.45703125,\n",
       "    285.6180114746094,\n",
       "    668.45703125,\n",
       "    'them',\n",
       "    3,\n",
       "    0,\n",
       "    8),\n",
       "   (288.1199645996094,\n",
       "    659.45703125,\n",
       "    294.6179504394531,\n",
       "    668.45703125,\n",
       "    'is',\n",
       "    3,\n",
       "    0,\n",
       "    9),\n",
       "   (297.1199645996094,\n",
       "    659.45703125,\n",
       "    307.12933349609375,\n",
       "    668.45703125,\n",
       "    'an',\n",
       "    3,\n",
       "    0,\n",
       "    10),\n",
       "   (309.6299743652344,\n",
       "    659.45703125,\n",
       "    344.1553649902344,\n",
       "    668.45703125,\n",
       "    'attention',\n",
       "    3,\n",
       "    0,\n",
       "    11),\n",
       "   (346.656005859375,\n",
       "    659.45703125,\n",
       "    366.1590576171875,\n",
       "    668.45703125,\n",
       "    'layer',\n",
       "    3,\n",
       "    0,\n",
       "    12),\n",
       "   (368.6610107421875,\n",
       "    659.45703125,\n",
       "    383.6715087890625,\n",
       "    668.45703125,\n",
       "    'that',\n",
       "    3,\n",
       "    0,\n",
       "    13),\n",
       "   (386.175048828125,\n",
       "    659.45703125,\n",
       "    407.6850280761719,\n",
       "    668.45703125,\n",
       "    'helps',\n",
       "    3,\n",
       "    0,\n",
       "    14),\n",
       "   (410.1870422363281,\n",
       "    659.45703125,\n",
       "    422.69842529296875,\n",
       "    668.45703125,\n",
       "    'the',\n",
       "    3,\n",
       "    0,\n",
       "    15),\n",
       "   (425.1990661621094,\n",
       "    659.45703125,\n",
       "    457.71612548828125,\n",
       "    668.45703125,\n",
       "    'decoder',\n",
       "    3,\n",
       "    0,\n",
       "    16),\n",
       "   (460.21807861328125,\n",
       "    659.45703125,\n",
       "    481.72808837890625,\n",
       "    668.45703125,\n",
       "    'focus',\n",
       "    3,\n",
       "    0,\n",
       "    17),\n",
       "   (484.2301025390625,\n",
       "    659.45703125,\n",
       "    494.2394714355469,\n",
       "    668.45703125,\n",
       "    'on',\n",
       "    3,\n",
       "    0,\n",
       "    18),\n",
       "   (496.7401123046875,\n",
       "    659.45703125,\n",
       "    528.7515869140625,\n",
       "    668.45703125,\n",
       "    'relevant',\n",
       "    3,\n",
       "    0,\n",
       "    19),\n",
       "   (70.5, 671.95703125, 90.50700378417969, 680.95703125, 'parts', 3, 1, 0),\n",
       "   (93.00900268554688,\n",
       "    671.95703125,\n",
       "    100.51348876953125,\n",
       "    680.95703125,\n",
       "    'of',\n",
       "    3,\n",
       "    1,\n",
       "    1),\n",
       "   (103.01699829101562,\n",
       "    671.95703125,\n",
       "    115.52836608886719,\n",
       "    680.95703125,\n",
       "    'the',\n",
       "    3,\n",
       "    1,\n",
       "    2),\n",
       "   (118.02899169921875,\n",
       "    671.95703125,\n",
       "    137.5394744873047,\n",
       "    680.95703125,\n",
       "    'input',\n",
       "    3,\n",
       "    1,\n",
       "    3),\n",
       "   (140.04298400878906,\n",
       "    671.95703125,\n",
       "    176.56634521484375,\n",
       "    680.95703125,\n",
       "    'sentence',\n",
       "    3,\n",
       "    1,\n",
       "    4),\n",
       "   (179.0669708251953,\n",
       "    671.95703125,\n",
       "    208.0560302734375,\n",
       "    680.95703125,\n",
       "    '(similar',\n",
       "    3,\n",
       "    1,\n",
       "    5),\n",
       "   (210.55795288085938,\n",
       "    671.95703125,\n",
       "    229.56443786621094,\n",
       "    680.95703125,\n",
       "    'what',\n",
       "    3,\n",
       "    1,\n",
       "    6),\n",
       "   (232.0679473876953,\n",
       "    671.95703125,\n",
       "    266.59332275390625,\n",
       "    680.95703125,\n",
       "    'attention',\n",
       "    3,\n",
       "    1,\n",
       "    7),\n",
       "   (269.09393310546875,\n",
       "    671.95703125,\n",
       "    288.6059265136719,\n",
       "    680.95703125,\n",
       "    'does',\n",
       "    3,\n",
       "    1,\n",
       "    8),\n",
       "   (291.1079406738281,\n",
       "    671.95703125,\n",
       "    298.1112976074219,\n",
       "    680.95703125,\n",
       "    'in',\n",
       "    3,\n",
       "    1,\n",
       "    9),\n",
       "   (300.6328125,\n",
       "    671.95703125,\n",
       "    334.6541748046875,\n",
       "    680.95703125,\n",
       "    'seq2seq',\n",
       "    3,\n",
       "    1,\n",
       "    10),\n",
       "   (337.1548156738281,\n",
       "    671.95703125,\n",
       "    366.16180419921875,\n",
       "    680.95703125,\n",
       "    'models',\n",
       "    3,\n",
       "    1,\n",
       "    11),\n",
       "   (368.68170166015625,\n",
       "    671.95703125,\n",
       "    518.729248046875,\n",
       "    680.95703125,\n",
       "    '(https://jalammar.github.io/visualizing-',\n",
       "    3,\n",
       "    1,\n",
       "    12),\n",
       "   (70.5,\n",
       "    684.45703125,\n",
       "    370.13031005859375,\n",
       "    693.45703125,\n",
       "    'neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)).',\n",
       "    3,\n",
       "    2,\n",
       "    0)]}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_text_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74b3b482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(70.5, 205.02610778808594, 79.166015625, 217.02610778808594, 'A', 0, 0, 0),\n",
       " (82.05670166015625,\n",
       "  205.02610778808594,\n",
       "  143.398681640625,\n",
       "  217.02610778808594,\n",
       "  'High-Level',\n",
       "  0,\n",
       "  0,\n",
       "  1),\n",
       " (146.7366943359375,\n",
       "  205.02610778808594,\n",
       "  175.40652465820312,\n",
       "  217.02610778808594,\n",
       "  'Look',\n",
       "  0,\n",
       "  0,\n",
       "  2),\n",
       " (70.5,\n",
       "  230.45704650878906,\n",
       "  89.34814453125,\n",
       "  239.45704650878906,\n",
       "  'Let’s',\n",
       "  1,\n",
       "  0,\n",
       "  0),\n",
       " (91.85014343261719,\n",
       "  230.45704650878906,\n",
       "  113.86550903320312,\n",
       "  239.45704650878906,\n",
       "  'begin',\n",
       "  1,\n",
       "  0,\n",
       "  1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_text_words[0]['words'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d972454",
   "metadata": {},
   "source": [
    "Extracting tables neatly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymupdf4llm.to_markdown(doc=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70044e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11718f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd636cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02cc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
